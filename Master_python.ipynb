{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Master Data Science Interviews.**\n",
    "*𝗣𝘆𝘁𝗵𝗼𝗻*\n",
    "- 👉 Master the fundamentals: syntax, loops, functions, and key data structures like lists, dictionaries, sets, and tuples\n",
    "- 👉 Dive into Pandas and NumPy for powerful data manipulation\n",
    "- 👉 Use Matplotlib and Seaborn for stunning data visualizations\n",
    "\n",
    "*𝗦𝘁𝗮𝘁𝗶𝘀𝘁𝗶𝗰𝘀 & 𝗣𝗿𝗼𝗯𝗮𝗯𝗶𝗹𝗶𝘁𝘆*\n",
    "- 👉 Grasp the essentials of descriptive statistics: mean, median, mode, and standard deviation\n",
    "- 👉 Understand probability theory: distributions, Bayes' theorem, and conditional probability\n",
    "- 👉 Master hypothesis testing and A/B testing for real-world applications\n",
    "\n",
    "*𝗠𝗮𝗰𝗵𝗶𝗻𝗲 𝗟𝗲𝗮𝗿𝗻𝗶𝗻𝗴*\n",
    "- 👉 Differentiate between supervised and unsupervised learning\n",
    "- 👉 Key algorithms to know: Linear & Logistic Regression, Decision Trees, Random Forest, KNN, and SVM\n",
    "- 👉 Learn model evaluation metrics: accuracy, precision, recall, F1 score, and ROC-AUC\n",
    "- 👉 Explore cross-validation and hyperparameter tuning to optimize models\n",
    "\n",
    "*𝗗𝗲𝗲𝗽 𝗟𝗲𝗮𝗿𝗻𝗶𝗻𝗴*\n",
    "- 👉 Understand neural networks and their architectures\n",
    "- 👉 Get hands-on with Keras and TensorFlow/PyTorch\n",
    "- 👉 Learn CNNs for image data and RNNs for sequence data\n",
    "\n",
    "*𝗗𝗮𝘁𝗮 𝗖𝗹𝗲𝗮𝗻𝗶𝗻𝗴 & 𝗙𝗲𝗮𝘁𝘂𝗿𝗲 𝗘𝗻𝗴𝗶𝗻𝗲𝗲𝗿𝗶𝗻𝗴*\n",
    "- 👉 Handle missing data, outliers, and data scaling effectively\n",
    "- 👉 Apply feature selection techniques (e.g., correlation, mutual information) to enhance model performance\n",
    "\n",
    "*𝗡𝗮𝘁𝘂𝗿𝗮𝗹 𝗟𝗮𝗻𝗴𝘂𝗮𝗴𝗲 𝗣𝗿𝗼𝗰𝗲𝘀𝘀𝗶𝗻𝗴 (𝗡𝗟𝗣)*\n",
    "- 👉 Get familiar with tokenization, stemming, and lemmatization\n",
    "- 👉 Understand Bag-of-Words and TF-IDF for text processing\n",
    "- 👉 Dive into sentiment analysis and topic modeling\n",
    "\n",
    "*𝗖𝗹𝗼𝘂𝗱 𝗮𝗻𝗱 𝗕𝗶𝗴 𝗗𝗮𝘁𝗮*\n",
    "- 👉 Explore cloud services (AWS, GCP, Azure) for data storage and computing\n",
    "- 👉 Work with distributed data using Spark\n",
    "- 👉 Master SQL for querying large datasets\n",
    "\n",
    "*The key is not to get overwhelmed. Start small, master one topic, and gradually move to the next. 📈*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_k_to_zero_array(nums, queries):\n",
    "    n = len(nums)\n",
    "    decrements = [0] * n  # Track total decrements for each index\n",
    "\n",
    "    for k, (l, r, val) in enumerate(queries, start=1):\n",
    "        # Apply the query to the decrements list\n",
    "        for i in range(l, r + 1):\n",
    "            decrements[i] += val\n",
    "\n",
    "        # Check if nums can be turned into a Zero Array\n",
    "        is_zero_array = True\n",
    "        for i in range(n):\n",
    "            if nums[i] - decrements[i] < 0:\n",
    "                is_zero_array = False\n",
    "                break\n",
    "            if nums[i] - decrements[i] != 0:\n",
    "                is_zero_array = False\n",
    "                break\n",
    "\n",
    "        if is_zero_array:\n",
    "            return k\n",
    "\n",
    "    # If no k found, return -1\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nums = [2,0,2] \n",
    "queries = [[0,2,1],[0,2,1],[1,1,3]]\n",
    "Solution().minZeroArray(nums=nums,queries=queries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solution(object):\n",
    "    def minZeroArray(self, nums, queries):\n",
    "        \"\"\"\n",
    "        :type nums: List[int]\n",
    "        :type queries: List[List[int]]\n",
    "        :rtype: int\n",
    "        \"\"\"\n",
    "        # If nums is already a zero array, return 0 immediately\n",
    "        if all(x == 0 for x in nums):\n",
    "            return 0\n",
    "        \n",
    "        def is_possible(nums, queries, k):\n",
    "            n = len(nums)\n",
    "            arr = nums[:]\n",
    "            diff = [0] * (n + 1)  # Difference array\n",
    "            \n",
    "            for i in range(k):\n",
    "                l, r, val = queries[i]\n",
    "                diff[l] -= val\n",
    "                diff[r + 1] += val\n",
    "            \n",
    "            curr_decrement = 0\n",
    "            for i in range(n):\n",
    "                curr_decrement += diff[i]\n",
    "                arr[i] += curr_decrement  # Apply decrement\n",
    "                if arr[i] > 0:\n",
    "                    return False  # If any element remains positive, k is not enough\n",
    "            \n",
    "            return True  # Successfully turned nums into a zero array\n",
    "        \n",
    "        left, right = 1, len(queries)\n",
    "        result = -1\n",
    "        \n",
    "        while left <= right:\n",
    "            mid = (left + right) // 2\n",
    "            if is_possible(nums, queries, mid):\n",
    "                result = mid\n",
    "                right = mid - 1  # Try for a smaller k\n",
    "            else:\n",
    "                left = mid + 1  # Increase k\n",
    "        \n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
